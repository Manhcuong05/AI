import joblib
from underthesea import word_tokenize
import re

def preprocess_text(text):
    """Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n gi·ªëng nh∆∞ khi train model."""
    stopwords = set(["l√†", "c·ªßa", "v√†", "ƒë√£", "c≈©ng", "n√†y", "ƒë∆∞·ª£c", "b·ªã", "v·ªõi", "cho", "c√≥"])
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)  # Lo·∫°i b·ªè d·∫•u c√¢u
    text = word_tokenize(text, format="text")  # T√°ch t·ª´ ti·∫øng Vi·ªát
    text = " ".join([word for word in text.split() if word not in stopwords])  # Lo·∫°i b·ªè stopwords
    return text

# Load m√¥ h√¨nh
model = joblib.load("sentiment_model.pkl")

def predict_sentiment(comment):
    """D·ª± ƒëo√°n c·∫£m x√∫c c·ªßa b√¨nh lu·∫≠n."""
    processed_comment = preprocess_text(comment)
    prediction = model.predict([processed_comment])[0]
    return prediction

# V√≠ d·ª• s·ª≠ d·ª•ng
if __name__ == "__main__":
    test_comment = "S·∫£n ph·∫©m n√†y d√πng r·∫•t t·ªá"
    sentiment = predict_sentiment(test_comment)
    print(f"üîç B√¨nh lu·∫≠n: {test_comment}")
    print(f"üí° C·∫£m x√∫c d·ª± ƒëo√°n: {sentiment}")
